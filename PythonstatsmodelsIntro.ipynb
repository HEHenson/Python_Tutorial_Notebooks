{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python modules for Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analytical techniques used by analysts to develop knowledge and information from data vary from the extremely simple to highly complex.  Most techniques that are available in commercially available packages are also to be found in Python, with the pandas and statsmodels library being central.  This note will briefly introduce these Python modules from the perspective of an analyst who is experienced with the standard statistical packages. \n",
    "\n",
    "This notebook is intended to complement an earlier notebook on the use of Python pandas to maintain databases. It will first load a database with artificial data.  This artificial data is created with interrelationships that will be revealed with subsequent analysis. However, the first step will be to perform the descriptive analysis to better understand the data.  Then there will be simple correlation analysis to scan for possible relationships between the variables in the database.  At this stage, the discussion will move from the pandas to another Python module, Statsmodels, which has a greater ability to analyze causality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Synthetic Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a synthetic database.  It will embed various relationships and properties within the data that the analytical techniques will uncover.  The creation of the database will also provide a forum to showcase the analytic abiities of the packages available in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create a random variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NumPy and pandas libraries can be used to generate random variables. NumPy contains many random number generators.  The most basic is shown below where a vector of 5 numbers is produced. These numbers will be uniformly distributed between zero and one and change each time the program is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.19536934  0.19425416  0.33397571  0.31237523  0.47295437]\n"
     ]
    }
   ],
   "source": [
    "# Create random variable\n",
    "import numpy as np\n",
    "print(np.random.rand(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To freeze the random numbers, it is necessary to set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.17022005e-01   7.20324493e-01   1.14374817e-04   3.02332573e-01\n",
      "   1.46755891e-01]\n"
     ]
    }
   ],
   "source": [
    "# fix the seed for the random numbers\n",
    "np.random.seed(1)\n",
    "print(np.random.rand(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now no matter how many times this notebook is run, the first element of the vector will always be 0.417.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a single random time series variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this test a normally distributed Pandas time series will be created over a 50 year period, starting in 1966.  Essential it is the same process as above, except that a date is used to index the value of the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2000    5.275718\n",
      "2001    3.909325\n",
      "2002    4.390015\n",
      "2003    5.306412\n",
      "2004    6.691826\n",
      "2005    4.252046\n",
      "Freq: A-DEC, Name: A1Y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a normally distributed random time series over a 50 year period starting in 1966\n",
    "import pandas as pd\n",
    "STARTYR = 1966\n",
    "YRNO = 50\n",
    "theyrper = pd.PeriodIndex(start=STARTYR, periods=YRNO,name='Year')\n",
    "A1Y = pd.Series(np.random.randn(YRNO)+5,index=theyrper,name='A1Y')\n",
    "print(A1Y['2000':'2005'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of important points here.  First the Pandas module is used to create a time series object of annual data.  However, is important to note that this a random variable with a mean of around 5 and distributed normally.  The above was just a print of six of the observations, as all 50 would have been too much. The above variable, A1Y, is independent, with a mean of five and a standard deviation of roughly one. This was achived with the use of randn, which has a mean of zero, and adding 5 to it.  The default standard deviation is one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create remaining 6 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2Y is created as a function of an error term A2E plus 0.5 of A1Y.  This creates a synthetic causal relationship that will be uncovered later on.  Note that it is necessary to add some randomness in the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2000    2.848761\n",
      "2001    2.376442\n",
      "2002    2.776933\n",
      "2003    2.242999\n",
      "2004    5.642779\n",
      "2005    3.814520\n",
      "Freq: A-DEC, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# A2Y will be a function of A1Y plus an error term\n",
    "A2E = pd.Series(np.random.randn(YRNO),index=theyrper,name='A2E')\n",
    "A2Y = 0.5 * A1Y + A2E\n",
    "print(A2Y['2000':'2005'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3Y will be a function of A1Y and A2Y.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2000     8.547386\n",
      "2001     7.482411\n",
      "2002     6.406746\n",
      "2003     8.745019\n",
      "2004     8.223193\n",
      "2005    15.623496\n",
      "Freq: A-DEC, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# A3Y will be a function of A1Y plus lag A2Y plus an error term\n",
    "A3E = pd.Series(np.random.randn(YRNO),index=theyrper,name='A3E')\n",
    "A3Y = 0.5 * A1Y + 2.0*A2Y.shift(1) + A3E\n",
    "print(A3Y['2000':'2005'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here A3Y is created from two variables plus another error term.  However, in this case the lagged value of A2Y is used via the shift member function. This has the important implication of reducing the number of observations by one as it is impossible to calculate A3Y with a lagged variable missing.In the previous section A1Y, A2Y, A3Y were added to the database. In this section, three more series are created B1Y, B2Y, B3Y with similar yet different characteristics. This will allow the demonstration of SciPy's ability to be used in the analysis of panel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a second dimension\n",
    "B1Y = pd.Series(np.random.randn(YRNO)*5+50,index=theyrper,name='B1Y')\n",
    "B2E = pd.Series(np.random.randn(YRNO),index=theyrper,name='B2E')\n",
    "B2Y = 2.0 * B1Y + B2E*5\n",
    "B3E = pd.Series(np.random.randn(YRNO),index=theyrper,name='B3E')\n",
    "B3Y = 0.5 * B1Y + 2.0*B2Y.shift(1) - A3Y + B3E*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This creates three new variables with similar relationships to above.  One new twist is the that A3Y has a negative impact on B3Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Six Time Series into Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have six data series that will now loaded into a single two dimensional DataFrame, theDF. Two create this DataFrame an index is created that allows for two layers of indexing.  One layer of indexing, designates the synthetic regions in this example as 'A' and 'B'.  The second layer, designates the industry as either one of three: 'Ind1','Ind2' and 'Ind3'.\n",
    "\n",
    "The DataFrame Ydf is created using a list of two lists designating the columns.  Then the time series are allocated to Ydf using a dictionary like syntax but with two elements, representing industry and region.  The dimensions of this database are 50 by 6, which are the years by the number variables. However, as we will see, the hierarchic indexing allows the analysis to resemble what is possible with a panel dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of Ydf are (50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create Tags for the two Regions A and B\n",
    "RegionTag = [ 'A' for letno in range(3) ] + [ 'B' for letno in range(3) ]\n",
    "IndTag = ['Ind1','Ind2','Ind3'] *2\n",
    " \n",
    "Ydf = pd.DataFrame(columns=[RegionTag,IndTag])\n",
    "Ydf.columns.names=['Region','Industry']\n",
    "Ydf['A','Ind1'] = A1Y\n",
    "Ydf['A','Ind2'] = A2Y\n",
    "Ydf['A','Ind3'] = A3Y\n",
    "Ydf['B','Ind1'] = B1Y\n",
    "Ydf['B','Ind2'] = B2Y\n",
    "Ydf['B','Ind3'] = B3Y\n",
    "del A1Y,A2Y,A3Y,B1Y,B2Y,B3Y\n",
    "print(\"The dimensions of Ydf are {}\".format(Ydf.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region  Industry\n",
       "A       Ind1        50\n",
       "        Ind2        50\n",
       "        Ind3        49\n",
       "B       Ind1        50\n",
       "        Ind2        50\n",
       "        Ind3        49\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate counts of observations\n",
    "Ydf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen by the count table above, the data is loaded in the pandas dataset.  Note that only 49 observations were available for both Ind3's as they were a function of the previous years value of their respective Ind2's.  As these did not exist in first year, 1966, the values are missing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th colspan=\"3\" halign=\"left\">A</th>\n",
       "      <th colspan=\"3\" halign=\"left\">B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industry</th>\n",
       "      <th>Ind1</th>\n",
       "      <th>Ind2</th>\n",
       "      <th>Ind3</th>\n",
       "      <th>Ind1</th>\n",
       "      <th>Ind2</th>\n",
       "      <th>Ind3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>3.894065</td>\n",
       "      <td>3.195332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.786271</td>\n",
       "      <td>93.411727</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>3.345485</td>\n",
       "      <td>0.915068</td>\n",
       "      <td>7.722578</td>\n",
       "      <td>57.997415</td>\n",
       "      <td>109.932382</td>\n",
       "      <td>204.240403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>2.636531</td>\n",
       "      <td>1.906560</td>\n",
       "      <td>3.635996</td>\n",
       "      <td>62.372097</td>\n",
       "      <td>113.960668</td>\n",
       "      <td>246.090013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>6.135345</td>\n",
       "      <td>3.414532</td>\n",
       "      <td>8.619865</td>\n",
       "      <td>48.338376</td>\n",
       "      <td>92.183413</td>\n",
       "      <td>249.007069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>3.982986</td>\n",
       "      <td>3.358526</td>\n",
       "      <td>8.889527</td>\n",
       "      <td>53.885733</td>\n",
       "      <td>99.237776</td>\n",
       "      <td>195.676484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Region           A                              B                        \n",
       "Industry      Ind1      Ind2      Ind3       Ind1        Ind2        Ind3\n",
       "Year                                                                     \n",
       "1966      3.894065  3.195332       NaN  43.786271   93.411727         NaN\n",
       "1967      3.345485  0.915068  7.722578  57.997415  109.932382  204.240403\n",
       "1968      2.636531  1.906560  3.635996  62.372097  113.960668  246.090013\n",
       "1969      6.135345  3.414532  8.619865  48.338376   92.183413  249.007069\n",
       "1970      3.982986  3.358526  8.889527  53.885733   99.237776  195.676484"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show missing first observations for variables function of lags\n",
    "Ydf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the above view of observation counts and actual values through time are organized by both Region and Industry. Although in creating Ydf the pandas panel option was not used, this use of a multilevel or heirarchic index gives credence to the desription of pandas as a panel dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2000    5.275718\n",
       "2001    3.909325\n",
       "2002    4.390015\n",
       "2003    5.306412\n",
       "2004    6.691826\n",
       "2005    4.252046\n",
       "Freq: A-DEC, Name: (A, Ind1), dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve individual time series from \n",
    "Ydf['A','Ind1']['2000':'2005']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there is a retrieval region, industry and time. The above example duplicates the values obtained above for A1Y. In a sense it does demonstrates the panel nature of pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any analysis can begin, it is always useful to calculate descriptive statistics.  The analysis at this stage will use the tools available in pandas.  However, in the final section on causality, the Statsmodels library will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region  Industry\n",
       "A       Ind1          4.993288\n",
       "        Ind2          2.743396\n",
       "        Ind3          8.082713\n",
       "B       Ind1         51.225903\n",
       "        Ind2        101.653703\n",
       "        Ind3        221.909325\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at means\n",
    "Ydf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th colspan=\"3\" halign=\"left\">A</th>\n",
       "      <th colspan=\"3\" halign=\"left\">B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industry</th>\n",
       "      <th>Ind1</th>\n",
       "      <th>Ind2</th>\n",
       "      <th>Ind3</th>\n",
       "      <th>Ind1</th>\n",
       "      <th>Ind2</th>\n",
       "      <th>Ind3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.993288</td>\n",
       "      <td>2.743396</td>\n",
       "      <td>8.082713</td>\n",
       "      <td>51.225903</td>\n",
       "      <td>101.653703</td>\n",
       "      <td>221.909325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.987552</td>\n",
       "      <td>1.008448</td>\n",
       "      <td>2.276365</td>\n",
       "      <td>4.453299</td>\n",
       "      <td>9.249725</td>\n",
       "      <td>20.149059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.636531</td>\n",
       "      <td>0.528250</td>\n",
       "      <td>3.635996</td>\n",
       "      <td>40.810122</td>\n",
       "      <td>85.231523</td>\n",
       "      <td>187.686389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.175472</td>\n",
       "      <td>2.023663</td>\n",
       "      <td>7.038333</td>\n",
       "      <td>48.496204</td>\n",
       "      <td>95.881541</td>\n",
       "      <td>205.552698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.063024</td>\n",
       "      <td>2.806173</td>\n",
       "      <td>8.135011</td>\n",
       "      <td>51.001967</td>\n",
       "      <td>100.819258</td>\n",
       "      <td>222.492180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.651554</td>\n",
       "      <td>3.400257</td>\n",
       "      <td>9.299919</td>\n",
       "      <td>53.863628</td>\n",
       "      <td>107.089306</td>\n",
       "      <td>234.760764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.042029</td>\n",
       "      <td>5.642779</td>\n",
       "      <td>15.623496</td>\n",
       "      <td>62.372097</td>\n",
       "      <td>128.483829</td>\n",
       "      <td>276.977423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Region            A                                B                        \n",
       "Industry       Ind1       Ind2       Ind3       Ind1        Ind2        Ind3\n",
       "count     50.000000  50.000000  49.000000  50.000000   50.000000   49.000000\n",
       "mean       4.993288   2.743396   8.082713  51.225903  101.653703  221.909325\n",
       "std        0.987552   1.008448   2.276365   4.453299    9.249725   20.149059\n",
       "min        2.636531   0.528250   3.635996  40.810122   85.231523  187.686389\n",
       "25%        4.175472   2.023663   7.038333  48.496204   95.881541  205.552698\n",
       "50%        5.063024   2.806173   8.135011  51.001967  100.819258  222.492180\n",
       "75%        5.651554   3.400257   9.299919  53.863628  107.089306  234.760764\n",
       "max        7.042029   5.642779  15.623496  62.372097  128.483829  276.977423"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ydf.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the analysts is happy with the initial descriptive statistics, then they may move on to an examination of the basic correlations.  This can be still effectively done in pandas, although at this point some analysts will want to move to another module, such a Statmodels, which we will see in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Between Individual Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation can exists between time series as well as between observations in the time series itself.  With pandas it is easy to examine the correlations between the variables themselves.  If we remember that A2Y was made a function of A1Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5319552897630998"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine correlation between two time series that are related by construction\n",
    "Ydf['A','Ind1'].corr(Ydf['A','Ind2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there is a very definite correlation that is in line with construction of the variable.  It is useful to compare with A1Y and B2Y, who are not correlated by construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.16205417914269171"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the correlation between two synthetic time series whose construction was independent\n",
    "Ydf['A','Ind1'].corr(Ydf['B','Ind1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, although the correlation is not zero, it is within the relm of what may have occured by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation within the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a small database of only six time series variables, pandas can provide a quick table for displaying the correlations within the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th colspan=\"3\" halign=\"left\">A</th>\n",
       "      <th colspan=\"3\" halign=\"left\">B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>Ind1</th>\n",
       "      <th>Ind2</th>\n",
       "      <th>Ind3</th>\n",
       "      <th>Ind1</th>\n",
       "      <th>Ind2</th>\n",
       "      <th>Ind3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th>Industry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">A</th>\n",
       "      <th>Ind1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.531955</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>-0.162054</td>\n",
       "      <td>-0.166880</td>\n",
       "      <td>0.012834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ind2</th>\n",
       "      <td>0.531955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221364</td>\n",
       "      <td>-0.153066</td>\n",
       "      <td>-0.169759</td>\n",
       "      <td>-0.074736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ind3</th>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.221364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112122</td>\n",
       "      <td>0.123070</td>\n",
       "      <td>-0.137632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">B</th>\n",
       "      <th>Ind1</th>\n",
       "      <td>-0.162054</td>\n",
       "      <td>-0.153066</td>\n",
       "      <td>0.112122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.844512</td>\n",
       "      <td>-0.059774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ind2</th>\n",
       "      <td>-0.166880</td>\n",
       "      <td>-0.169759</td>\n",
       "      <td>0.123070</td>\n",
       "      <td>0.844512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.106321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ind3</th>\n",
       "      <td>0.012834</td>\n",
       "      <td>-0.074736</td>\n",
       "      <td>-0.137632</td>\n",
       "      <td>-0.059774</td>\n",
       "      <td>-0.106321</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Region                  A                             B                    \n",
       "Industry             Ind1      Ind2      Ind3      Ind1      Ind2      Ind3\n",
       "Region Industry                                                            \n",
       "A      Ind1      1.000000  0.531955  0.184400 -0.162054 -0.166880  0.012834\n",
       "       Ind2      0.531955  1.000000  0.221364 -0.153066 -0.169759 -0.074736\n",
       "       Ind3      0.184400  0.221364  1.000000  0.112122  0.123070 -0.137632\n",
       "B      Ind1     -0.162054 -0.153066  0.112122  1.000000  0.844512 -0.059774\n",
       "       Ind2     -0.166880 -0.169759  0.123070  0.844512  1.000000 -0.106321\n",
       "       Ind3      0.012834 -0.074736 -0.137632 -0.059774 -0.106321  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show database\n",
    "Ydf.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table is similar to what would be produced in most statistics packages. The correlation between A1Y and A2Y is 0.53, as was shown with the individual examinations.  Similarly, the low correlation between A1Y and A2Y is shown as well.\n",
    "\n",
    "This form of analysis shows it value when the higher correlations jump out, such as B1Y and B2Y.  However, if the database were substantially larger, then it would be more practical to use other packages than Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this section is to demonstrate that many of the tools that applied analysts use in the business world exist within the Python ecosystem.  However, it is important to note that causality is a big issue, and this note will not resolve it. It will only display some of the rudimentary tools. \n",
    "\n",
    "By construction A1Y had a positive influence on A2Y.  This can be confirmed with regression analysis. It is possible to do some of the regression in analysis in pandas. However, at this point it is useful to demonstrate that the analysis can be done in the StatModel package that is focussed on the application of statistical techniques, rather than using the capabilities that exist in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Simple Causal Relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas data is easily analysed with the module Statsmodels. First the data needs to be extracted to a timeseries variable, then it is included in a standard regression formulation.  Note, that even this step may been unnecessary with other means of constructing Ydf.\n",
    "\n",
    "The regression is run below with the fit() command, which returns the results as an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    A2Y   R-squared:                       0.283\n",
      "Model:                            OLS   Adj. R-squared:                  0.268\n",
      "Method:                 Least Squares   F-statistic:                     18.94\n",
      "Date:                Mon, 04 Sep 2017   Prob (F-statistic):           7.02e-05\n",
      "Time:                        18:31:07   Log-Likelihood:                -62.546\n",
      "No. Observations:                  50   AIC:                             129.1\n",
      "Df Residuals:                      48   BIC:                             132.9\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.0310      0.635      0.049      0.961      -1.246       1.308\n",
      "A1Y            0.5432      0.125      4.352      0.000       0.292       0.794\n",
      "==============================================================================\n",
      "Omnibus:                        1.817   Durbin-Watson:                   2.084\n",
      "Prob(Omnibus):                  0.403   Jarque-Bera (JB):                1.102\n",
      "Skew:                          -0.339   Prob(JB):                        0.576\n",
      "Kurtosis:                       3.263   Cond. No.                         27.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Run regression of A2Y against A1Y.\n",
    "import statsmodels.formula.api as smf\n",
    "# extract time series for regression\n",
    "A2Y = Ydf['A','Ind2']\n",
    "A1Y = Ydf['A','Ind1']\n",
    "mod_A2Y_A1Y = smf.ols(formula='A2Y ~ A1Y' , data=Ydf).fit()\n",
    "print(mod_A2Y_A1Y.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above the Python statsmodel module produces regression results similar to what would be obtained with a commercial package.  However, as the module is open source, a dedicated analyst would have the freedom to modify the contents of the output. There are some key points to note:\n",
    "* The interface between the pandas module and statsmodels is reasonable.  \n",
    "* The command interface is very similar to R\n",
    "* The estimated coefficient of 0.54 is reasonable close to the \"true\" coefficient used to generate the data\n",
    "    * The significance test suggests that it is unlikely the value is zero\n",
    "* The \"true\" constant was 0 and the estimated value is not significantly different than zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above regression results was based on two variables known to be related. In the second case, A1Y and B1Y were not correlated.  This is confirmed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    A1Y   R-squared:                       0.026\n",
      "Model:                            OLS   Adj. R-squared:                  0.006\n",
      "Method:                 Least Squares   F-statistic:                     1.295\n",
      "Date:                Mon, 04 Sep 2017   Prob (F-statistic):              0.261\n",
      "Time:                        18:31:07   Log-Likelihood:                -69.150\n",
      "No. Observations:                  50   AIC:                             142.3\n",
      "Df Residuals:                      48   BIC:                             146.1\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      6.8342      1.624      4.208      0.000       3.569      10.099\n",
      "B1Y           -0.0359      0.032     -1.138      0.261      -0.099       0.028\n",
      "==============================================================================\n",
      "Omnibus:                        1.429   Durbin-Watson:                   1.991\n",
      "Prob(Omnibus):                  0.490   Jarque-Bera (JB):                1.058\n",
      "Skew:                           0.007   Prob(JB):                        0.589\n",
      "Kurtosis:                       2.287   Cond. No.                         600.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# regression where correlation is spurious\n",
    "# recover time series for regression\n",
    "B1Y = Ydf['B','Ind1']\n",
    "A1Y = Ydf['A','Ind1']\n",
    "mod_A1Y_B1Y = smf.ols(formula='A1Y ~ B1Y', data=Ydf).fit()\n",
    "print(mod_A1Y_B1Y.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the coefficient on B1Y was virtually zero.  This is expected by construction with an intercept of close to the synthetic value.  The strongest causal relation that appeared in the correlation matrix was between B1Y and B2Y.  As seen below, a tighter R-squared and test of significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    B2Y   R-squared:                       0.713\n",
      "Model:                            OLS   Adj. R-squared:                  0.707\n",
      "Method:                 Least Squares   F-statistic:                     119.4\n",
      "Date:                Mon, 04 Sep 2017   Prob (F-statistic):           1.29e-14\n",
      "Time:                        18:31:07   Log-Likelihood:                -150.45\n",
      "No. Observations:                  50   AIC:                             304.9\n",
      "Df Residuals:                      48   BIC:                             308.7\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     11.7987      8.255      1.429      0.159      -4.799      28.396\n",
      "B1Y            1.7541      0.161     10.925      0.000       1.431       2.077\n",
      "==============================================================================\n",
      "Omnibus:                        0.029   Durbin-Watson:                   2.077\n",
      "Prob(Omnibus):                  0.986   Jarque-Bera (JB):                0.083\n",
      "Skew:                          -0.042   Prob(JB):                        0.959\n",
      "Kurtosis:                       2.819   Cond. No.                         600.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# regression with very strong relation\n",
    "B2Y = Ydf['B','Ind2']\n",
    "B1Y = Ydf['B','Ind1']\n",
    "mod_B2Y_B1Y = smf.ols(formula='B2Y ~ B1Y', data=Ydf).fit()\n",
    "print(mod_B2Y_B1Y.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a far tighter fit as evidenced by the higher R-square and test statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Multiple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above regression only examined the relationship between pairs of variables.  However, more complex relationships can be examined.  Below we estimate the relationships between B3Y and the variables that went into its construction.  Here three exogenous variables contribute to its value.  Of particular note is B2Y where the shift member function is used to allow for the lag effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    B3Y   R-squared:                       0.945\n",
      "Model:                            OLS   Adj. R-squared:                  0.941\n",
      "Method:                 Least Squares   F-statistic:                     257.4\n",
      "Date:                Mon, 04 Sep 2017   Prob (F-statistic):           2.48e-28\n",
      "Time:                        18:31:07   Log-Likelihood:                -145.15\n",
      "No. Observations:                  49   AIC:                             298.3\n",
      "Df Residuals:                      45   BIC:                             305.9\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       -4.8996     12.350     -0.397      0.693     -29.774      19.975\n",
      "B1Y              0.3934      0.164      2.400      0.021       0.063       0.724\n",
      "B2Y.shift(1)     2.0964      0.076     27.479      0.000       1.943       2.250\n",
      "A3Y             -0.7919      0.312     -2.539      0.015      -1.420      -0.164\n",
      "==============================================================================\n",
      "Omnibus:                        2.348   Durbin-Watson:                   2.141\n",
      "Prob(Omnibus):                  0.309   Jarque-Bera (JB):                1.575\n",
      "Skew:                           0.204   Prob(JB):                        0.455\n",
      "Kurtosis:                       2.222   Cond. No.                     2.03e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.03e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# multiple regression with a lagged variable\n",
    "B3Y = Ydf['B','Ind3']\n",
    "B1Y = Ydf['B','Ind1']\n",
    "B2Y = Ydf['B','Ind2']\n",
    "A3Y = Ydf['A','Ind3']\n",
    "mod_B3Y = smf.ols(formula='B3Y ~ B1Y + B2Y.shift(1) + A3Y', data=Ydf).fit()\n",
    "print(mod_B3Y.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluding Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The above demonstrates that Python is a viable environment to do statistical basic analysis.  It may be many years before the thousands of models available in packages such as R, are available to Python users.  Still, the basic models are there and in an environment that is relatively easy to use if the investment in Python has already been made."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
